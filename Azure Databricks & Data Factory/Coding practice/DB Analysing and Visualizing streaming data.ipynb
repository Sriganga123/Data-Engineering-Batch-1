{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d7a3a38-4cf5-44ef-9943-0bf9a629814d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing and Visualizing streaming data\n"
     ]
    }
   ],
   "source": [
    "print(\"Analysing and Visualizing streaming data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c89ab23c-43f6-439e-8182-e80b67595a9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Create a streaming DataFrame using the 'rate' source\n",
    "streaming_df = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 10).load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d7344f-5d7b-4756-81fd-150ee6f675c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform aggregation to count records per timestamp window\n",
    "windowed_count = streaming_df.groupBy(window(\"timestamp\", \"1 minute\")).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9339dbc-96f1-4f68-879a-71d19249610d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = windowed_count.writeStream.format(\"memory\").queryName(\"windowed_counts\").outputMode(\"complete\").start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5be23cb5-8073-4203-8542-a3f87cb980a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>window</th><th>count</th></tr></thead><tbody><tr><td>List(2024-02-19T04:14:00.000+0000, 2024-02-19T04:15:00.000+0000)</td><td>439</td></tr><tr><td>List(2024-02-19T04:15:00.000+0000, 2024-02-19T04:16:00.000+0000)</td><td>421</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "2024-02-19T04:14:00.000+0000",
          "2024-02-19T04:15:00.000+0000"
         ],
         439
        ],
        [
         [
          "2024-02-19T04:15:00.000+0000",
          "2024-02-19T04:16:00.000+0000"
         ],
         421
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"spark.timeWindow\":true}",
         "name": "window",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"start\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"end\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM windowed_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d6f4fda-371e-466d-bbd8-42c7e7e20889",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example-2\n",
    "\n",
    "# Writing a stream of data to table and analysing it\n",
    "\n",
    "streamingDf = spark.readStream.format(\"rate\").load()\n",
    "stream = streamingDf.selectExpr(\"value as id\").writeStream.format(\"delta\").option(\"checkpointLocation\", \"/tmp/checkpoint\").start(\"/tmp/delta-tablex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1cf705d-d034-43ec-a921-12d98ea22f2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "136ea34e-e1b9-4d34-92b4-f567850a3a50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read a stream of changes from table\n",
    "\n",
    "stream2 = spark.readStream.format(\"delta\").load(\"/tmp/delta-tablex\").writeStream.format(\"console\").start()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1474251131860815,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Analysing and Visualizing streaming data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
