{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267899b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c981ac8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-HPGQI4S:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Group by</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d0000b2650>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Group by\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96afbe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[(\"Chandu\",\"Data Science\",10000),\n",
    "     (\"Chandu\",\"IOT\",5000),\n",
    "     (\"Rohith\",\"Big Data\",4000),\n",
    "     (\"Chandu\",\"Big Data\",4000),\n",
    "     (\"Rohith\",\"Big Data\",3000),\n",
    "     (\"Krishna\",\"Data Science\",20000),\n",
    "     (\"Krishna\",\"IOT\",10000),\n",
    "     (\"Krishna\",\"Big Data\",5000),\n",
    "     (\"Rashmi\",\"Data Science\",10000),\n",
    "     (\"Rashmi\",\"Big Data\",2000)]\n",
    "\n",
    "columns=[\"Name\",\"Departments\",\"Salary\"]\n",
    "df=spark.createDataFrame(data=data,schema=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16ce1872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|   Name| Departments|Salary|\n",
      "+-------+------------+------+\n",
      "| Chandu|Data Science| 10000|\n",
      "| Chandu|         IOT|  5000|\n",
      "| Rohith|    Big Data|  4000|\n",
      "| Chandu|    Big Data|  4000|\n",
      "| Rohith|    Big Data|  3000|\n",
      "|Krishna|Data Science| 20000|\n",
      "|Krishna|         IOT| 10000|\n",
      "|Krishna|    Big Data|  5000|\n",
      "| Rashmi|Data Science| 10000|\n",
      "| Rashmi|    Big Data|  2000|\n",
      "+-------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72564a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|sum(Salary)|\n",
      "+------------+-----------+\n",
      "|Data Science|      40000|\n",
      "|         IOT|      15000|\n",
      "|    Big Data|      18000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using group by\n",
    "# 1) sum()\n",
    "df.groupBy(\"Departments\").sum(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3fb8f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|min(Salary)|\n",
      "+------------+-----------+\n",
      "|Data Science|      10000|\n",
      "|         IOT|       5000|\n",
      "|    Big Data|       2000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) min()\n",
    "df.groupBy(\"Departments\").min(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a23bf85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|max(Salary)|\n",
      "+------------+-----------+\n",
      "|Data Science|      20000|\n",
      "|         IOT|      10000|\n",
      "|    Big Data|       5000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) max()\n",
    "df.groupBy(\"Departments\").max(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0985689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "| Departments|       avg(Salary)|\n",
      "+------------+------------------+\n",
      "|Data Science|13333.333333333334|\n",
      "|         IOT|            7500.0|\n",
      "|    Big Data|            3600.0|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4) avg\n",
    "df.groupBy(\"Departments\").avg(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62ab140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "| Departments|       avg(Salary)|\n",
      "+------------+------------------+\n",
      "|Data Science|13333.333333333334|\n",
      "|         IOT|            7500.0|\n",
      "|    Big Data|            3600.0|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5) mean()\n",
    "df.groupBy(\"Departments\").mean(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d56a62dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| Departments|count|\n",
      "+------------+-----+\n",
      "|Data Science|    3|\n",
      "|         IOT|    2|\n",
      "|    Big Data|    5|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6) count()\n",
    "df.groupBy(\"Departments\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40f9b1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+\n",
      "| Departments|Salary_sum|Min_Salary|\n",
      "+------------+----------+----------+\n",
      "|Data Science|     40000|     10000|\n",
      "|         IOT|     15000|      5000|\n",
      "|    Big Data|     18000|      2000|\n",
      "+------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7) agg\n",
    "df.groupBy(\"Departments\").agg(sum(df.Salary).alias(\"Salary_sum\"),min(df.Salary).alias(\"Min_Salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "254a505f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+-------+------+------+\n",
      "| Departments|Chandu|Krishna|Rashmi|Rohith|\n",
      "+------------+------+-------+------+------+\n",
      "|         IOT|  5000|  10000|  NULL|  NULL|\n",
      "|    Big Data|  4000|   5000|  2000|  7000|\n",
      "|Data Science| 10000|  20000| 10000|  NULL|\n",
      "+------------+------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8) pivot()\n",
    "#aggregation where one of the grouping column values is transposed into individual columns with distinct data\n",
    "df.groupBy(\"Departments\").pivot(\"Name\").sum(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b427148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|   Name| Departments|Salary|\n",
      "+-------+------------+------+\n",
      "| Rashmi|    Big Data|  2000|\n",
      "| Rohith|    Big Data|  3000|\n",
      "| Rohith|    Big Data|  4000|\n",
      "| Chandu|    Big Data|  4000|\n",
      "|Krishna|    Big Data|  5000|\n",
      "| Chandu|         IOT|  5000|\n",
      "| Rashmi|Data Science| 10000|\n",
      "|Krishna|         IOT| 10000|\n",
      "| Chandu|Data Science| 10000|\n",
      "|Krishna|Data Science| 20000|\n",
      "+-------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# orderBy and sort()\n",
    "# Sort based on single column\n",
    "df.sort(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99a6427d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|   Name| Departments|Salary|\n",
      "+-------+------------+------+\n",
      "|Krishna|Data Science| 20000|\n",
      "| Chandu|Data Science| 10000|\n",
      "|Krishna|         IOT| 10000|\n",
      "| Rashmi|Data Science| 10000|\n",
      "| Chandu|         IOT|  5000|\n",
      "|Krishna|    Big Data|  5000|\n",
      "| Chandu|    Big Data|  4000|\n",
      "| Rohith|    Big Data|  4000|\n",
      "| Rohith|    Big Data|  3000|\n",
      "| Rashmi|    Big Data|  2000|\n",
      "+-------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sorting in descending order\n",
    "df.sort(df.Salary.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c81fc6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|   Name| Departments|Salary|\n",
      "+-------+------------+------+\n",
      "| Rashmi|    Big Data|  2000|\n",
      "| Rohith|    Big Data|  3000|\n",
      "| Rohith|    Big Data|  4000|\n",
      "| Chandu|    Big Data|  4000|\n",
      "|Krishna|    Big Data|  5000|\n",
      "| Chandu|Data Science| 10000|\n",
      "| Rashmi|Data Science| 10000|\n",
      "|Krishna|Data Science| 20000|\n",
      "| Chandu|         IOT|  5000|\n",
      "|Krishna|         IOT| 10000|\n",
      "+-------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort based on first column and then on second column\n",
    "df.sort(df.Departments,df.Salary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcdf7e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|   Name| Departments|Salary|\n",
      "+-------+------------+------+\n",
      "| Rashmi|    Big Data|  2000|\n",
      "| Rohith|    Big Data|  3000|\n",
      "| Rohith|    Big Data|  4000|\n",
      "| Chandu|    Big Data|  4000|\n",
      "|Krishna|    Big Data|  5000|\n",
      "| Chandu|Data Science| 10000|\n",
      "| Rashmi|Data Science| 10000|\n",
      "|Krishna|Data Science| 20000|\n",
      "| Chandu|         IOT|  5000|\n",
      "|Krishna|         IOT| 10000|\n",
      "+-------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# orderBy can also be used in place of sort()\n",
    "df.orderBy(df.Departments,df.Salary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e63739c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+---+\n",
      "|   Name| Departments|Salary|Age|\n",
      "+-------+------------+------+---+\n",
      "| Chandu|Data Science| 10000| 25|\n",
      "| Chandu|         IOT|  5000| 25|\n",
      "| Rohith|    Big Data|  4000| 25|\n",
      "| Chandu|    Big Data|  4000| 25|\n",
      "| Rohith|    Big Data|  3000| 25|\n",
      "|Krishna|Data Science| 20000| 25|\n",
      "|Krishna|         IOT| 10000| 25|\n",
      "|Krishna|    Big Data|  5000| 25|\n",
      "| Rashmi|Data Science| 10000| 25|\n",
      "| Rashmi|    Big Data|  2000| 25|\n",
      "+-------+------------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding columns to dataframe\n",
    "# 1) adding column to dataframe with constant value\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "df.withColumn(\"Age\",lit(25)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d27c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+----------+\n",
      "|   Name| Departments|Salary|New Salary|\n",
      "+-------+------------+------+----------+\n",
      "| Chandu|Data Science| 10000|     30000|\n",
      "| Chandu|         IOT|  5000|     25000|\n",
      "| Rohith|    Big Data|  4000|     24000|\n",
      "| Chandu|    Big Data|  4000|     24000|\n",
      "| Rohith|    Big Data|  3000|     23000|\n",
      "|Krishna|Data Science| 20000|     40000|\n",
      "|Krishna|         IOT| 10000|     30000|\n",
      "|Krishna|    Big Data|  5000|     25000|\n",
      "| Rashmi|Data Science| 10000|     30000|\n",
      "| Rashmi|    Big Data|  2000|     22000|\n",
      "+-------+------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) Add Column Based on Another Column of DataFrame\n",
    "# (i) Using withColumn() method\n",
    "df.withColumn(\"New Salary\",df.Salary+20000).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "049e280b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+-------------+\n",
      "|   Name| Departments|Salary|      Details|\n",
      "+-------+------------+------+-------------+\n",
      "| Chandu|Data Science| 10000| Chandu-10000|\n",
      "| Chandu|         IOT|  5000|  Chandu-5000|\n",
      "| Rohith|    Big Data|  4000|  Rohith-4000|\n",
      "| Chandu|    Big Data|  4000|  Chandu-4000|\n",
      "| Rohith|    Big Data|  3000|  Rohith-3000|\n",
      "|Krishna|Data Science| 20000|Krishna-20000|\n",
      "|Krishna|         IOT| 10000|Krishna-10000|\n",
      "|Krishna|    Big Data|  5000| Krishna-5000|\n",
      "| Rashmi|Data Science| 10000| Rashmi-10000|\n",
      "| Rashmi|    Big Data|  2000|  Rashmi-2000|\n",
      "+-------+------------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ii) using concat_ws\n",
    "from pyspark.sql.functions import concat_ws\n",
    "df.withColumn(\"Details\",concat_ws(\"-\",\"Name\",\"Salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45c94205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+---+\n",
      "|   Name| Departments|Salary|Age|\n",
      "+-------+------------+------+---+\n",
      "| Chandu|Data Science| 10000| 45|\n",
      "| Chandu|         IOT|  5000| 45|\n",
      "| Rohith|    Big Data|  4000| 45|\n",
      "| Chandu|    Big Data|  4000| 45|\n",
      "| Rohith|    Big Data|  3000| 45|\n",
      "|Krishna|Data Science| 20000| 45|\n",
      "|Krishna|         IOT| 10000| 45|\n",
      "|Krishna|    Big Data|  5000| 45|\n",
      "| Rashmi|Data Science| 10000| 45|\n",
      "| Rashmi|    Big Data|  2000| 45|\n",
      "+-------+------------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) Add column when not exists on dataframe\n",
    "if \"Age\" not in df.columns:\n",
    "    df.withColumn(\"Age\",lit(45)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8209d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "| Krish|  31|        10| 30000|\n",
      "|  Sona|  30|         8| 25000|\n",
      "|  Mona|  29|         4| 20000|\n",
      "| Dhana|  24|         3| 20000|\n",
      "|  Raju|  21|         1| 15000|\n",
      "| Bannu|  23|         2| 18000|\n",
      "|Chinnu|NULL|      NULL| 48999|\n",
      "|  NULL|  34|        10| 38000|\n",
      "|  NULL|  36|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Handling Missing values\n",
    "\n",
    "# Creating a dataframe containing null values\n",
    "df1=spark.read.csv(\"C:\\\\Users\\\\DELL\\\\OneDrive\\\\Desktop\\\\Data Engineering Python\\\\DEPython\\\\mising.csv\",header=True,inferSchema=True)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a803a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Krish| 31|        10| 30000|\n",
      "| Sona| 30|         8| 25000|\n",
      "| Mona| 29|         4| 20000|\n",
      "|Dhana| 24|         3| 20000|\n",
      "| Raju| 21|         1| 15000|\n",
      "|Bannu| 23|         2| 18000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Dropping rows based on null values\n",
    "df1.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9e2930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "| Krish|  31|        10| 30000|\n",
      "|  Sona|  30|         8| 25000|\n",
      "|  Mona|  29|         4| 20000|\n",
      "| Dhana|  24|         3| 20000|\n",
      "|  Raju|  21|         1| 15000|\n",
      "| Bannu|  23|         2| 18000|\n",
      "|Chinnu|NULL|      NULL| 48999|\n",
      "|  NULL|  34|        10| 38000|\n",
      "|  NULL|  36|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## if all values in rows are null then drop otherwise by default any\n",
    "df1.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "065e8381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "| Krish|  31|        10| 30000|\n",
      "|  Sona|  30|         8| 25000|\n",
      "|  Mona|  29|         4| 20000|\n",
      "| Dhana|  24|         3| 20000|\n",
      "|  Raju|  21|         1| 15000|\n",
      "| Bannu|  23|         2| 18000|\n",
      "|Chinnu|NULL|      NULL| 48999|\n",
      "|  NULL|  34|        10| 38000|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#atleast 2 non null values should be present. \n",
    "\n",
    "df1.na.drop(how=\"any\",thresh=2).show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf1d523e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Krish| 31|        10| 30000|\n",
      "| Sona| 30|         8| 25000|\n",
      "| Mona| 29|         4| 20000|\n",
      "|Dhana| 24|         3| 20000|\n",
      "| Raju| 21|         1| 15000|\n",
      "|Bannu| 23|         2| 18000|\n",
      "| NULL| 34|        10| 38000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only in that column rows get deleted\n",
    "\n",
    "df1.na.drop(how=\"any\",subset=[\"Experience\"]).show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7e5ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Joining pyspark dataframes\n",
    "\n",
    "# create a dataframe for employee\n",
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \n",
    "    ]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\",\"emp_dept_id\",\"gender\",\"salary\"]\n",
    "empDF=spark.createDataFrame(data=emp,schema=empColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f50ee95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(empDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb7c71d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4fa696df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dept_name: string, dept_id: bigint]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe for department\n",
    "\n",
    "dept = [(\"Finance\",10), \n",
    "    (\"Marketing\",20), \n",
    "    (\"Sales\",30), \n",
    "    (\"IT\",40) \n",
    "  ]\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF=spark.createDataFrame(data=dept,schema=deptColumns)\n",
    "deptDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d67947d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deptDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c919f71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 1) Inner Join\n",
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id,\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c41ad1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|  NULL|    NULL|           NULL|       NULL|       NULL|  NULL|  NULL|    Sales|     30|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     NULL|   NULL|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|  NULL|    NULL|           NULL|       NULL|       NULL|  NULL|  NULL|    Sales|     30|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     NULL|   NULL|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|  NULL|    NULL|           NULL|       NULL|       NULL|  NULL|  NULL|    Sales|     30|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     NULL|   NULL|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) Full outer join\n",
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id,\"outer\").show()\n",
    "                # or\n",
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id,\"full\").show()\n",
    "                # or\n",
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id,\"fullouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ae535da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     NULL|   NULL|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     NULL|   NULL|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) Left outer join\n",
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id,\"left\").show()\n",
    "                # or\n",
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id,\"leftouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b3266a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|  NULL|    NULL|           NULL|       NULL|       NULL|  NULL|  NULL|    Sales|     30|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|  NULL|    NULL|           NULL|       NULL|       NULL|  NULL|  NULL|    Sales|     30|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4) Right outer join\n",
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id,\"right\").show()\n",
    "                # or\n",
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id,\"rightouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "551354c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5) Left semi join\n",
    "#returns columns from the only left dataset for the records match in the right dataset on join expression, \n",
    "#records not matched on join expression are ignored from both left and right datasets.\n",
    "\n",
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id,\"leftsemi\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19a82fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|emp_id| name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|     6|Brown|              2|       2010|         50|      |    -1|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6) Left Anti join\n",
    "#leftanti join does the exact opposite of the leftsemi\n",
    "#leftanti join returns only columns from the left dataset for non-matched records.\n",
    "\n",
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.dept_id,\"leftanti\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fc10998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+\n",
      "| ID|  Name|  Company|\n",
      "+---+------+---------+\n",
      "|  1|  Sona|      TCS|\n",
      "|  2|  Mona|  Infosys|\n",
      "|  3| Bannu| Delloite|\n",
      "|  4| Sunny|      TCS|\n",
      "|  5|Chinnu|Accenture|\n",
      "+---+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example-2 on joins\n",
    "\n",
    "# Creating a datframe for Employee Personal Details\n",
    "data=[(\"1\",\"Sona\",\"TCS\"),\n",
    "      (\"2\",\"Mona\",\"Infosys\"),\n",
    "      (\"3\",\"Bannu\",\"Delloite\"),\n",
    "     (\"4\",\"Sunny\",\"TCS\"),\n",
    "     (\"5\",\"Chinnu\",\"Accenture\")]\n",
    "cols=[\"ID\",\"Name\",\"Company\"]\n",
    "df1=spark.createDataFrame(data,cols)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6d627df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()\n",
    "print(type(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "687e4ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+\n",
      "| ID|Salary|Department|\n",
      "+---+------+----------+\n",
      "|  1| 45000|        HR|\n",
      "|  2| 90000|   Manager|\n",
      "|  6| 78000|        IT|\n",
      "|  5| 50000|     Sales|\n",
      "+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe of employee salary details\n",
    "data=[(\"1\",45000,\"HR\"),\n",
    "     (\"2\",90000,\"Manager\"),\n",
    "     (\"6\",78000,\"IT\"),\n",
    "     (\"5\",50000,\"Sales\")]\n",
    "\n",
    "cols=[\"ID\",\"Salary\",\"Department\"]\n",
    "df2=spark.createDataFrame(data=data,schema=cols)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dc83c79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Salary: long (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()\n",
    "print(type(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "18405218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+---+------+----------+\n",
      "| ID|  Name|  Company| ID|Salary|Department|\n",
      "+---+------+---------+---+------+----------+\n",
      "|  1|  Sona|      TCS|  1| 45000|        HR|\n",
      "|  2|  Mona|  Infosys|  2| 90000|   Manager|\n",
      "|  5|Chinnu|Accenture|  5| 50000|     Sales|\n",
      "+---+------+---------+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Inner join\n",
    "df1.join(df2,df1.ID==df2.ID,\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "755faca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---------+----+------+----------+\n",
      "|  ID|  Name|  Company|  ID|Salary|Department|\n",
      "+----+------+---------+----+------+----------+\n",
      "|   1|  Sona|      TCS|   1| 45000|        HR|\n",
      "|   2|  Mona|  Infosys|   2| 90000|   Manager|\n",
      "|   3| Bannu| Delloite|NULL|  NULL|      NULL|\n",
      "|   4| Sunny|      TCS|NULL|  NULL|      NULL|\n",
      "|   5|Chinnu|Accenture|   5| 50000|     Sales|\n",
      "|NULL|  NULL|     NULL|   6| 78000|        IT|\n",
      "+----+------+---------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) outer join\n",
    "df1.join(df2,df1.ID==df2.ID,\"outer\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "66c60dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+----+------+----------+\n",
      "| ID|  Name|  Company|  ID|Salary|Department|\n",
      "+---+------+---------+----+------+----------+\n",
      "|  1|  Sona|      TCS|   1| 45000|        HR|\n",
      "|  2|  Mona|  Infosys|   2| 90000|   Manager|\n",
      "|  3| Bannu| Delloite|NULL|  NULL|      NULL|\n",
      "|  4| Sunny|      TCS|NULL|  NULL|      NULL|\n",
      "|  5|Chinnu|Accenture|   5| 50000|     Sales|\n",
      "+---+------+---------+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) left join\n",
    "df1.join(df2,df1.ID==df2.ID,\"leftouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f2fdec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---------+---+------+----------+\n",
      "|  ID|  Name|  Company| ID|Salary|Department|\n",
      "+----+------+---------+---+------+----------+\n",
      "|   1|  Sona|      TCS|  1| 45000|        HR|\n",
      "|   2|  Mona|  Infosys|  2| 90000|   Manager|\n",
      "|NULL|  NULL|     NULL|  6| 78000|        IT|\n",
      "|   5|Chinnu|Accenture|  5| 50000|     Sales|\n",
      "+----+------+---------+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4) Right join\n",
    "df1.join(df2,df1.ID==df2.ID,\"right\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "679f969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+\n",
      "| ID|  Name|  Company|\n",
      "+---+------+---------+\n",
      "|  1|  Sona|      TCS|\n",
      "|  2|  Mona|  Infosys|\n",
      "|  5|Chinnu|Accenture|\n",
      "+---+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5) left semi\n",
    "df1.join(df2,df1.ID==df2.ID,\"leftsemi\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7ad2431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------+\n",
      "| ID| Name| Company|\n",
      "+---+-----+--------+\n",
      "|  3|Bannu|Delloite|\n",
      "|  4|Sunny|     TCS|\n",
      "+---+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6) left anti\n",
    "df1.join(df2,df1.ID==df2.ID,\"leftanti\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e160f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4cd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
